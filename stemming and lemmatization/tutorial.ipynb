{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy doesn't allow stemming but nltk does. since both stemming and lemmatization is important we are going to use nltk for stemming and spacy for lemma..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "eats | eat\n",
      "eat | eat\n",
      "ate | ate\n",
      "adjustable | adjust\n",
      "rafting | raft\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = ['eating','eats','eat','ate','adjustable','rafting','ability','meeting']\n",
    "for word in words:\n",
    "    print(word,'|',stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stemming is just removing the suffix and prefix from the word where the base word remains. but it always doesn't work, like 'ability' and 'ate' it converted it into 'abil' which doesn't mean anything and 'ate' which is not a base word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here spacy lammatization comes in handy. which use lingual rules to convert into base word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat | 9837207709914848172\n",
      "eats | eat | 9837207709914848172\n",
      "eat | eat | 9837207709914848172\n",
      "ate | eat | 9837207709914848172\n",
      "adjustable | adjustable | 6033511944150694480\n",
      "rafting | raft | 7154368781129989833\n",
      "ability | ability | 11565809527369121409\n",
      "meeting | meeting | 14798207169164081740\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('eating eats eat ate adjustable rafting ability meeting')\n",
    "for token in doc:\n",
    "    print(token,'|',token.lemma_,'|',token.lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "though it fixes the previous issue with nltk stemming . here new issue is it's not converting each word to it's base like 'meeting' to 'meet' and 'adjustable' to 'adjust'. that's why both stemming and lemma is important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In projects we'll do stemming first then lemma.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customize lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | bro\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brah\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      ". | .\n",
      "I | I\n",
      "'m | be\n",
      "exhuasted | exhuaste\n"
     ]
    }
   ],
   "source": [
    "doc_ = nlp('Bro, you wanna go? Brah, don\\'t say no. I\\'m exhuasted')\n",
    "for token in doc_:\n",
    "    print(token,'|',token.lemma_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add([[{'TEXT':'Bro'}],[{'TEXT':'Brah'}]],{'LEMMA':'Brother'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro | Brother\n",
      ", | ,\n",
      "you | you\n",
      "wanna | wanna\n",
      "go | go\n",
      "? | ?\n",
      "Brah | Brother\n",
      ", | ,\n",
      "do | do\n",
      "n't | not\n",
      "say | say\n",
      "no | no\n",
      ". | .\n",
      "I | I\n",
      "'m | be\n",
      "exhuasted | exhuaste\n"
     ]
    }
   ],
   "source": [
    "doc_2 = nlp('Bro, you wanna go? Brah, don\\'t say no. I\\'m exhuasted')\n",
    "for token in doc_2:\n",
    "    print(token,'|',token.lemma_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
